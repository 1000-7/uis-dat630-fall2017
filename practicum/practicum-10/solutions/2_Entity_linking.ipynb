{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Linking in Queries\n",
    "\n",
    "A set of queries is given in `data/queries_el.txt`, with the corresponding relevance judgments in `data/qrels_el.csv`.  Your task is to:\n",
    "\n",
    "  1. Annotate these queries with entities using the [Nordlys API](http://nordlys.readthedocs.io/en/latest/restful_api.html#api-el) using two different models:\n",
    "    - The default model (which is CMNS)\n",
    "    - The more advanced LTR method\n",
    "  2. Evaluate the models in terms of precision, recall, and F1.\n",
    "    - Considering $g$ as set of annotated entitites according to ground truth and $s$ as set of entities identified by system, we compute precison and recall for each query as:\n",
    "    - $P_q = \\frac{|g \\cap s|}{|g|}$ and  $R_q = \\frac{|g \\cap s|}{|s|}$\n",
    "    - When precision and recall are not defined (a query has empty $g$ and $s$ sets), the query gets values $0$ or $1$ for both precision and recall.\n",
    "    - The overall precision and recall is micro-averaged over all queires.\n",
    "  3. Try LTR with thresholds $0.4$ and $0.01$ and compare the results with the default LTR results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUERIES_FILE = \"data/queries_el.txt\"\n",
    "QRELS_FILE = \"data/qrels_el.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Results\n",
    "\n",
    "Overall results:\n",
    "\n",
    "| Model | P | R | F1 |\n",
    "| -- | -- | -- | -- | \n",
    "| CMNS | 0.3611 | 0.4011 | 0.3801 |\n",
    "| LTR  | 0.8056 | 0.7822 | 0.7937 |\n",
    "\n",
    "Results for LTR with thesholds 0.4 and 0.01:\n",
    "\n",
    "| Model | P | R | F1 |\n",
    "| -- | -- | -- | -- | \n",
    "| LTR-0.4 | 0.6667 | 0.6233 | 0.6443 |\n",
    "| LTR-0.01 | 0.5722 | 0.6389 | 0.6037|\n",
    "| LTR-0.1 | 0.8056 | 0.7822 | 0.7937 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
