{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a custom retrieval method based on term statistics from Elasticsearch\n",
    "\n",
    "  1. Implement the TF-IDF weighting formula by completing the `score()` method.\n",
    "      \n",
    "  2. Implement Language Modeling (query (log)likelihood) scoring as a new `score_lm()` method.\n",
    "  \n",
    "  3. Implement BM25 scoring as a new `score_bm25()` method.\n",
    "\n",
    "\n",
    "We use documents by taking the dot product of query and document term weights: $score(q,d)=\\sum_{t \\in q}w_{t,q} w_{t,d}$.\n",
    "Different retrieval models can be instantiated by setting these weights as follows:\n",
    "\n",
    "| Retrieval Model | $w_{t,q}$ | $w_{t,d}$ |\n",
    "| -- | -- | -- |\n",
    "| TF-IDF | $f_{t,q}$ | $\\frac{f_{t,d}}{|d|} IDF_t$ |\n",
    "| LM | $f_{t,q}$ | $\\log \\Big( (1-\\lambda) \\frac{f_{t,d}}{|d|} + \\lambda \\frac{f_{t,C}}{cl} \\Big)$ |\n",
    "| BM25 | $f_{t,q}$ | $\\frac{f_{t,d} (1+k_1)}{f_{t,d} + k_1(1-b+b\\frac{|d|}{avgdl})} \\times IDF_t$ |\n",
    "\n",
    " - $f_{t,q}$ is the frequency of term t in query q\n",
    " - $f_{t,d}$ is the frequency of term t in document d\n",
    " - $f_{t,C}$ is the frequency of term t in the entire collection\n",
    " - $IDF_{t}=\\log \\frac{N}{df_t}$\n",
    " - $N$ is the total number of documents in the collection\n",
    " - $df_t$ is the number of documents that contain term t\n",
    " - $|d|$ is the length of document d\n",
    " - $cl$ collection length (sum of all document lengths $\\sum_{d'}|d|$)\n",
    " - $\\lambda$ is a smoothing parameter\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import pprint\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INDEX_NAME = \"aquaint\"\n",
    "DOC_TYPE = \"doc\"\n",
    "FIELD = \"content\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring method\n",
    "\n",
    "This is our \"custom\" scoring method. \n",
    "  - `es` is an Elasticsearch object; this is needed for getting term statistics from Elasticsearch.\n",
    "  - `qterms` holds a sequence of query terms. It is important that these terms must be analyzed the same way documents were analyzed during indexing.\n",
    "  - `doc_id` is the document's ID.\n",
    "  \n",
    "The scoring method computes the dot product between the query term weights and document term weights: $score(q,d)=\\sum_{t \\in q}w_{t,q} w_{t,d}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_tfidf(es, qterms, doc_id):\n",
    "    # Total number of documents in the index\n",
    "    N = es.count(index=INDEX_NAME, doc_type=DOC_TYPE)[\"count\"]\n",
    "\n",
    "    # Getting term frequency statistics for the given document field from Elasticsearch\n",
    "    tv = es.termvectors(index=INDEX_NAME, doc_type=DOC_TYPE, id=doc_id, fields=[FIELD],\n",
    "                              term_statistics=True).get(\"term_vectors\", {}).get(FIELD, {})\n",
    "    \n",
    "    # uncomment to see what information ES returns\n",
    "    #pprint.pprint(tv)\n",
    "        \n",
    "    dl = sum([s[\"term_freq\"] for t, s in tv[\"terms\"].items()])  # length of the document\n",
    "    cl = tv[\"field_statistics\"][\"sum_ttf\"]  # collection length (total number of terms in a given field in all documents)\n",
    "    avg_dl = cl / N\n",
    "    \n",
    "    s = 0  # holds the retrieval score\n",
    "    for t in qterms:\n",
    "        df_t = tv[\"terms\"][t][\"doc_freq\"]  # number of docs in the collection that contain that term\n",
    "        f_td = tv[\"terms\"][t][\"term_freq\"]  # raw frequenct of t in d (number of times term t appears in doc d)\n",
    "        t_tC = tv[\"terms\"][t][\"ttf\"]  # frequency of t in the entire collection\n",
    "        \n",
    "        w_tq = 1\n",
    "        idf_t = math.log(N / df_t, 2)\n",
    "        w_td = f_td / dl * idf_t\n",
    "        s += w_tq * w_td\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LM\n",
    "\n",
    "The smoothing parameter $\\lambda$ is set to 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_lm(es, qterms, doc_id):\n",
    "    # Total number of documents in the index\n",
    "    N = es.count(index=INDEX_NAME, doc_type=DOC_TYPE)[\"count\"]\n",
    "\n",
    "    # Getting term frequency statistics for the given document field from Elasticsearch\n",
    "    tv = es.termvectors(index=INDEX_NAME, doc_type=DOC_TYPE, id=doc_id, fields=[FIELD],\n",
    "                              term_statistics=True).get(\"term_vectors\", {}).get(FIELD, {})\n",
    "    \n",
    "    dl = sum([s[\"term_freq\"] for t, s in tv[\"terms\"].items()])  # length of the document\n",
    "    cl = tv[\"field_statistics\"][\"sum_ttf\"]  # collection length (total number of terms in a given field in all documents)\n",
    "    avg_dl = cl / N\n",
    "    \n",
    "    lambd = 0.1\n",
    "    \n",
    "    s = 0  # holds the retrieval score\n",
    "    for t in qterms:\n",
    "        df_t = tv[\"terms\"][t][\"doc_freq\"]  # number of docs in the collection that contain that term\n",
    "        f_td = tv[\"terms\"][t][\"term_freq\"]  # raw frequenct of t in d (number of times term t appears in doc d)\n",
    "        t_tC = tv[\"terms\"][t][\"ttf\"]  # frequency of t in the entire collection\n",
    "        \n",
    "        w_tq = 1\n",
    "        w_td = math.log((1-lambd) * f_td / dl + lambd * t_tC / cl, 2)\n",
    "        s += w_tq * w_td\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25\n",
    "\n",
    "We use standard parameter settings, `k1=1.2`, `b=0.75`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_bm25(es, qterms, doc_id):\n",
    "    # Total number of documents in the index\n",
    "    N = es.count(index=INDEX_NAME, doc_type=DOC_TYPE)[\"count\"]\n",
    "\n",
    "    # Getting term frequency statistics for the given document field from Elasticsearch\n",
    "    tv = es.termvectors(index=INDEX_NAME, doc_type=DOC_TYPE, id=doc_id, fields=[FIELD],\n",
    "                              term_statistics=True).get(\"term_vectors\", {}).get(FIELD, {})\n",
    "    \n",
    "    dl = sum([s[\"term_freq\"] for t, s in tv[\"terms\"].items()])  # length of the document\n",
    "    cl = tv[\"field_statistics\"][\"sum_ttf\"]  # collection length (total number of terms in a given field in all documents)\n",
    "    avg_dl = cl / N\n",
    "    \n",
    "    k1 = 1.2\n",
    "    b = 0.75\n",
    "    \n",
    "    s = 0  # holds the retrieval score\n",
    "    for t in qterms:\n",
    "        df_t = tv[\"terms\"][t][\"doc_freq\"]  # number of docs in the collection that contain that term\n",
    "        f_td = tv[\"terms\"][t][\"term_freq\"]  # raw frequenct of t in d (number of times term t appears in doc d)\n",
    "        t_tC = tv[\"terms\"][t][\"ttf\"]  # frequency of t in the entire collection\n",
    "        \n",
    "        w_tq = 1\n",
    "        idf_t = math.log(N / df_t, 2)\n",
    "        B = 1 - b + b * dl / avg_dl\n",
    "        w_td = (f_td * (k1+1)) / (f_td + k1 * B) * idf_t\n",
    "        s += w_tq * w_td\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query analyzer\n",
    "\n",
    "See [indices.analyze](https://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.client.IndicesClient.analyze)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyze_query(es, query):\n",
    "    tokens = es.indices.analyze(index=INDEX_NAME, body={\"text\": query})[\"tokens\"]\n",
    "    query_terms = []\n",
    "    for t in sorted(tokens, key=lambda x: x[\"position\"]):\n",
    "        query_terms.append(t[\"token\"])\n",
    "    return query_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "es = Elasticsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"tropical storms\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the top-1 document using Elasticsearch\n",
    "\n",
    "We search a single field (set in `FIELD`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = es.search(index=INDEX_NAME, q=query, df=FIELD, _source=False, size=1).get(\"hits\", {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the ID of the first hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APW19990810.0014\n"
     ]
    }
   ],
   "source": [
    "doc_id = res[\"hits\"][0][\"_id\"]\n",
    "print(doc_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-score this document using our own retrieval method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to transform the query string into a sequence of query terms, using the same analysis procedure that was used for building the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tropical', 'storms']\n"
     ]
    }
   ],
   "source": [
    "qterms = analyze_query(es, query)\n",
    "print(qterms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we compute the \"custom\" retrieval score for this document using different scoring methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF: 0.4001095.3\n",
      "LM:     -10.8930615.3\n",
      "BM25:   30.8231875.3\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF: %f5.3\" % score_tfidf(es, qterms, doc_id))\n",
    "print(\"LM:     %f5.3\" % score_lm(es, qterms, doc_id))\n",
    "print(\"BM25:   %f5.3\" % score_bm25(es, qterms, doc_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
